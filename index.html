<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> NLP4Health Lab Amsterdam </title> <meta name="author" content="Iacer Calixto"> <meta name="description" content="The NLP4Health Lab Amsterdam is located at the Amsterdam UMC in the University of Amsterdam and conducts cutting-edge research on human-centric and responsible Natural Language Processing (NLP) and Machine Learning (ML) methods for high-stakes applications with a strong focus on healthcare applications. The Lab is lead by dr. Iacer Calixto. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://nlp4health-lab.github.io/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?bf50d6d9dd867d3e0f3b0add94449649"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/activities/">activities </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">people </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/team/">our team</a> <a class="dropdown-item " href="/team/principal-investigator">principal investigator</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> NLP4Health Lab Amsterdam </h1> <p class="desc"><a href="https://researchinformation.amsterdamumc.org/en/organisations/medical-informatics-amc" rel="external nofollow noopener" target="_blank">Dept. of Medical Informatics, AUMC, University of Amsterdam</a>. Meibergdreef 9, 1105 AZ, Amsterdam.</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/team_icalixto_600x450px-480.webp 480w,/assets/img/team_icalixto_600x450px-800.webp 800w,/assets/img/team_icalixto_600x450px-1400.webp 1400w," sizes="(min-width: 800px) 231.0px, (min-width: 576px) 30vw, 95vw" type="image/webp"> <img src="/assets/img/team_icalixto_600x450px.jpg?63dab5d05df14ce698aca2dc911408e1" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="team_icalixto_600x450px.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div class="clearfix"> <p>Welcome to the website of the NLP4Health Lab Amsterdam led by <a href="team/principal-investigator">dr. Iacer Calixto</a>! We are part of the <a href="https://www.amc.nl/web/research-75/departments/medical-informatics-1/methods-in-medical-informatics.htm" rel="external nofollow noopener" target="_blank">Methods in Medical Informatics</a> research line in the <a href="https://www.amc.nl/web/research-75/departments/medical-informatics-1.htm" rel="external nofollow noopener" target="_blank">Department of Medical Informatics</a>, <a href="https://www.amsterdamumc.org/en/research.htm" rel="external nofollow noopener" target="_blank">Amsterdam UMC</a>, in the <a href="https://www.uva.nl/en/" rel="external nofollow noopener" target="_blank">University of Amsterdam</a>. We conduct cutting-edge research on human-centric and responsible Natural Language Processing (NLP) and Machine Learning (ML) methods for healthcare and other high-stakes applications.</p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Jun 12, 2025</th> <td> <a href="https://scholar.google.com/citations?user=dvDEcd0AAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Arnisa Fazla</a> and <a href="https://www.linkedin.com/in/max-pop0v/" rel="external nofollow noopener" target="_blank">Maxim Popov</a> officially joined our lab as PhD students last month! Arnisa works in the <a href="projects/carenlp_project">CaRe-NLP project</a> and Max in the <a href="projects/medispeech_project">Medispeech project</a>. Arnisa will work on methods for annotation disagreement and uncertainty quantification with LLMs in healthcare, and Max will work on methods that bridge automatic speech recognition and NLP to automate reporting and reduce clinicians’ administrative burden. Welcome, Arnisa and Max! </td> </tr> <tr> <th scope="row" style="width: 20%">Dec 01, 2024</th> <td> <a href="https://albertotestoni.github.io/" rel="external nofollow noopener" target="_blank">Alberto Testoni</a> officially started working in the <a href="projects/carenlp_project">CaRe-NLP project</a> as a post-doctoral researcher. Alberto has a background in computer and cognitive science, and in his work he will focus on NLP and its intersection with multimodal learning. Welcome, Alberto! </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 01, 2024</th> <td> <a href="https://www.linkedin.com/in/hossboll/" rel="external nofollow noopener" target="_blank">Heloísa Oss Boll</a> and <a href="https://www.linkedin.com/in/xinlan-yan-a1b467214/" rel="external nofollow noopener" target="_blank">Xinlan Yan</a> officially start working in the <a href="projects/carenlp_project">CaRe-NLP project</a>. Heloísa focuses on devising LLMs for clinical tasks and Xinlan on synthetic data generation with privacy-preserving methods. Both PhD candidates are co-supervised with <a href="https://scholar.google.nl/citations?user=lymnZacAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">prof. Ameen Abu-Hanna</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 01, 2024</th> <td> <strong>We are hiring!</strong> We are currently looking for 2 PhD students to work on the NWO-funded <a href="/projects/carenlp_project">CaRe-NLP</a> project. </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 01, 2023</th> <td> The <a href="/projects/carenlp_project">CaRe-NLP</a> project was awarded funding by NWO (with co-funding from the Amsterdam UMC and the Department of Medical Informatics). We will hire 3 more PhD students and 1 post-doctoral researcher over the next years. Stay tuned! </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/LLM-aided_Tab3-480.webp 480w,/assets/img/publication_preview/LLM-aided_Tab3-800.webp 800w,/assets/img/publication_preview/LLM-aided_Tab3-1400.webp 1400w," sizes="80vw,80vh" type="image/webp"> <img src="/assets/img/publication_preview/LLM-aided_Tab3.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="LLM-aided_Tab3.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="mishra-etal-2023-llm" class="col-sm-8"> <div class="title">LLM aided semi-supervision for efficient Extractive Dialog Summarization</div> <div class="author"> Nishant Mishra ,  Gaurav Sahu ,  <em>Iacer Calixto</em> ,  Ameen Abu-Hanna ,  and  Issam Laradji </div> <div class="periodical"> <em>In Findings of the Association for Computational Linguistics: EMNLP 2023</em> , Dec 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.18653/v1/2023.findings-emnlp.670" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Generating high-quality summaries for chat dialogs often requires large labeled datasets. We propose a method to efficiently use unlabeled data for extractive summarization of customer-agent dialogs. In our method, we frame summarization as a question-answering problem and use state-of-the-art large language models (LLMs) to generate pseudo-labels for a dialog. We then use these pseudo-labels to fine-tune a chat summarization model, effectively transferring knowledge from the large LLM into a smaller specialized model. We demonstrate our method on the TWEETSUMM dataset, and show that using 10% of the original labelled data set we can achieve 65.9/57.0/61.0 ROUGE-1/-2/-L, whereas the current state-of-the-art trained on the entire training data set obtains 65.16/55.81/64.37 ROUGE-1/-2/-L. In other words, in the worst case (i.e., ROUGE-L) we still effectively retain 94.7% of the performance while using only 10% of the data.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">mishra-etal-2023-llm</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{LLM} aided semi-supervision for efficient Extractive Dialog Summarization}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Mishra, Nishant and Sahu, Gaurav and Calixto, Iacer and Abu-Hanna, Ameen and Laradji, Issam}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Bouamor, Houda and Pino, Juan and Bali, Kalika}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Findings of the Association for Computational Linguistics: EMNLP 2023}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">dec</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Singapore}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2023.findings-emnlp.670}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.18653/v1/2023.findings-emnlp.670}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{10002--10009}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/dormosh-etal-fig1-480.webp 480w,/assets/img/publication_preview/dormosh-etal-fig1-800.webp 800w,/assets/img/publication_preview/dormosh-etal-fig1-1400.webp 1400w," sizes="80vw,80vh" type="image/webp"> <img src="/assets/img/publication_preview/dormosh-etal-fig1.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="dormosh-etal-fig1.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="10.1093/ageing/afae016" class="col-sm-8"> <div class="title">Topic evolution before fall incidents in new fallers through natural language processing of general practitioners’ clinical notes</div> <div class="author"> Noman Dormosh ,  Ameen Abu-Hanna ,  <em>Iacer Calixto</em> ,  Martijn C Schut ,  Martijn W Heymans ,  and  Nathalie Velde </div> <div class="periodical"> <em>Age and Ageing</em>, Feb 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1093/ageing/afae016" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Falls involve dynamic risk factors that change over time, but most studies on fall-risk factors are cross-sectional and do not capture this temporal aspect. The longitudinal clinical notes within electronic health records (EHR) provide an opportunity to analyse fall risk factor trajectories through Natural Language Processing techniques, specifically dynamic topic modelling (DTM). This study aims to uncover fall-related topics for new fallers and track their evolving trends leading up to falls.This case–cohort study utilised primary care EHR data covering information on older adults between 2016 and 2019. Cases were individuals who fell in 2019 but had no falls in the preceding three years (2016–18). The control group was randomly sampled individuals, with similar size to the cases group, who did not endure falls during the whole study follow-up period. We applied DTM on the clinical notes collected between 2016 and 2018. We compared the trend lines of the case and control groups using the slopes, which indicate direction and steepness of the change over time.A total of 2,384 fallers (cases) and an equal number of controls were included. We identified 25 topics that showed significant differences in trends between the case and control groups. Topics such as medications, renal care, family caregivers, hospital admission/discharge and referral/streamlining diagnostic pathways exhibited a consistent increase in steepness over time within the cases group before the occurrence of falls.Early recognition of health conditions demanding care is crucial for applying proactive and comprehensive multifactorial assessments that address underlying causes, ultimately reducing falls and fall-related injuries.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">10.1093/ageing/afae016</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Dormosh, Noman and Abu-Hanna, Ameen and Calixto, Iacer and Schut, Martijn C and Heymans, Martijn W and van der Velde, Nathalie}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Topic evolution before fall incidents in new fallers through natural language processing of general practitioners’ clinical notes}}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Age and Ageing}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{53}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{afae016}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">feb</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1468-2834}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1093/ageing/afae016}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1093/ageing/afae016}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{https://academic.oup.com/ageing/article-pdf/53/2/afae016/56669437/afae016.pdf}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/ViLMA-Figure1-480.webp 480w,/assets/img/publication_preview/ViLMA-Figure1-800.webp 800w,/assets/img/publication_preview/ViLMA-Figure1-1400.webp 1400w," sizes="80vw,80vh" type="image/webp"> <img src="/assets/img/publication_preview/ViLMA-Figure1.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ViLMA-Figure1.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="kesen-etal-2024vilma" class="col-sm-8"> <div class="title">ViLMA: A Zero-Shot Benchmark for Linguistic and Temporal Grounding in Video-Language Models</div> <div class="author"> Ilker Kesen ,  Andrea Pedrotti ,  Mustafa Dogan ,  Michele Cafagna ,  Emre Can Acikgoz ,  Letitia Parcalabescu ,  <em>Iacer Calixto</em> ,  Anette Frank , and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Albert Gatt, Aykut Erdem, Erdem Erkut' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In The Twelfth International Conference on Learning Representations</em> , Feb 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openreview.net/forum?id=liuqDwmbQJ" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">kesen-etal-2024vilma</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Vi{LMA}: A Zero-Shot Benchmark for Linguistic and Temporal Grounding in Video-Language Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kesen, Ilker and Pedrotti, Andrea and Dogan, Mustafa and Cafagna, Michele and Acikgoz, Emre Can and Parcalabescu, Letitia and Calixto, Iacer and Frank, Anette and Gatt, Albert and Erdem, Aykut and Erkut, Erdem}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The Twelfth International Conference on Learning Representations}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=liuqDwmbQJ}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/NNLG_Figure1-480.webp 480w,/assets/img/publication_preview/NNLG_Figure1-800.webp 800w,/assets/img/publication_preview/NNLG_Figure1-1400.webp 1400w," sizes="80vw,80vh" type="image/webp"> <img src="/assets/img/publication_preview/NNLG_Figure1.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="NNLG_Figure1.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="10.1613/jair.1.12918" class="col-sm-8"> <div class="title">Neural Natural Language Generation: A Survey on Multilinguality, Multimodality, Controllability and Learning</div> <div class="author"> Erkut Erdem ,  Menekse Kuyu ,  Semih Yagcioglu ,  Anette Frank ,  Letitia Parcalabescu ,  Barbara Plank ,  Andrii Babii ,  Oleksii Turuta , and <span class="more-authors" title="click to view 10 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '10 more authors' ? 'Aykut Erdem, Iacer Calixto, Elena Lloret, Elena-Simona Apostol, Ciprian-Octavian Truică, Branislava Šandrih, Sanda Martinčić-Ipšić, Gábor Berend, Albert Gatt, Grăzina Korvel' : '10 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">10 more authors</span> </div> <div class="periodical"> <em>J. Artif. Int. Res.</em>, May 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.jair.org/index.php/jair/article/view/12918" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1613/jair.1.12918" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Developing artificial learning systems that can understand and generate natural language has been one of the long-standing goals of artificial intelligence. Recent decades have witnessed an impressive progress on both of these problems, giving rise to a new family of approaches. Especially, the advances in deep learning over the past couple of years have led to neural approaches to natural language generation (NLG). These methods combine generative language learning techniques with neural-networks based frameworks. With a wide range of applications in natural language processing, neural NLG (NNLG) is a new and fast growing field of research. In this state-of-the-art report, we investigate the recent developments and applications of NNLG in its full extent from a multidimensional view, covering critical perspectives such as multimodality, multilinguality, controllability and learning strategies. We summarize the fundamental building blocks of NNLG approaches from these aspects and provide detailed reviews of commonly used preprocessing steps and basic neural architectures. This report also focuses on the seminal applications of these NNLG models such as machine translation, description generation, automatic speech recognition, abstractive summarization, text simplification, question answering and generation, and dialogue generation. Finally, we conclude with a thorough discussion of the described frameworks by pointing out some open research directions.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">10.1613/jair.1.12918</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Erdem, Erkut and Kuyu, Menekse and Yagcioglu, Semih and Frank, Anette and Parcalabescu, Letitia and Plank, Barbara and Babii, Andrii and Turuta, Oleksii and Erdem, Aykut and Calixto, Iacer and Lloret, Elena and Apostol, Elena-Simona and Truic\u{a}, Ciprian-Octavian and \v{S}andrih, Branislava and Martin\v{c}i\'{c}-Ip\v{s}i\'{c}, Sanda and Berend, G\'{a}bor and Gatt, Albert and Korvel, Gr\u{a}zina}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Neural Natural Language Generation: A Survey on Multilinguality, Multimodality, Controllability and Learning}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">issue_date</span> <span class="p">=</span> <span class="s">{May 2022}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{AI Access Foundation}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{El Segundo, CA, USA}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{73}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1076-9757}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1613/jair.1.12918}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1613/jair.1.12918}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{J. Artif. Int. Res.}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{77}</span><span class="p">,</span>
  <span class="na">alt_metric</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{natural language, neural networks}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/NLP-for-mental-health_Fig1-480.webp 480w,/assets/img/publication_preview/NLP-for-mental-health_Fig1-800.webp 800w,/assets/img/publication_preview/NLP-for-mental-health_Fig1-1400.webp 1400w," sizes="80vw,80vh" type="image/webp"> <img src="/assets/img/publication_preview/NLP-for-mental-health_Fig1.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="NLP-for-mental-health_Fig1.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="2436/624261" class="col-sm-8"> <div class="title">Natural language processing for mental disorders: an overview</div> <div class="author"> <em>Iacer Calixto</em> ,  Viktoriya Yaneva ,  and  Raphael Cardoso </div> <div class="periodical"> <em>In Natural Language Processing in Healthcare: A Special Focus on Low Resource Languages</em> , May 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.taylorfrancis.com/chapters/edit/10.1201/9781003138013-3/natural-language-processing-mental-disorders-overview-iacer-calixto-victoria-yaneva-raphael-moura-cardoso" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p> In recent years, there has been a surge in interest in using natural language processing (NLP) applications for clinical psychology and psychiatry. Despite the increased societal, economic, and academic interest, there has been no systematic critical analysis of the recent progress in NLP applications for mental disorders, or of the resources available for training and evaluating such systems. This chapter addresses this gap through two main contributions. First, it provides an overview of the NLP literature related to mental disorders, with a focus on autism, dyslexia, schizophrenia, depression and mental health in general. We discuss the strengths and shortcomings of current methodologies, specifically focusing on the challenges in obtaining large volumes of high-quality domain-specific data both for English and for lower-resource languages. We also provide a list of datasets publicly available for researchers who would like to develop NLP methods for specific mental disorders, categorized according to relevant criteria such as data source, language, annotation, and size. Our second contribution is a discussion on how to support the application of these methods to various languages and social contexts. This includes recommendations on conducting robust and ethical experiments from a machine learning perspective, and a discussion on how techniques such as cross-lingual transfer learning could be applied within this area. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@incollection</span><span class="p">{</span><span class="nl">2436/624261</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Calixto, Iacer and Yaneva, Viktoriya and Cardoso, Raphael}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Natural language processing for mental disorders: an overview}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{CRC Press}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Natural Language Processing in Healthcare: A Special Focus on Low Resource Languages}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{37-59}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9780367685393}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1201/9781003138013}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://hdl.handle.net/2436/624261}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/VidLM_Table1-480.webp 480w,/assets/img/publication_preview/VidLM_Table1-800.webp 800w,/assets/img/publication_preview/VidLM_Table1-1400.webp 1400w," sizes="80vw,80vh" type="image/webp"> <img src="/assets/img/publication_preview/VidLM_Table1.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="VidLM_Table1.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="Zonneveld_2023_ICCV" class="col-sm-8"> <div class="title">Video-and-Language (VidL) models and their cognitive relevance</div> <div class="author"> Anne Zonneveld ,  Albert Gatt ,  and  <em>Iacer Calixto</em> </div> <div class="periodical"> <em>In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) Workshops</em> , Oct 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://sites.google.com/view/iccv-mmfm/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>In this paper we give a narrative review of multi-modal video-language (VidL) models. We introduce the current landscape of VidL models and benchmarks, and draw inspiration from neuroscience and cognitive science to propose avenues for future research in VidL models in particular and artificial intelligence (AI) in general. We argue that iterative feedback loops between AI, neuroscience, and cognitive science are essential to spur progress across these disciplines. We motivate why we focus specifically on VidL models and their benchmarks as a promising type of model to bring improvements in AI and categorise current VidL efforts across multiple’cognitive relevance axioms’. Finally, we provide suggestions on how to effectively incorporate this interdisciplinary viewpoint into research on VidL models in particular and AI in general. In doing so, we hope to create awareness of the potential of VidL models to narrow the gap between neuroscience, cognitive science, and AI.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Zonneveld_2023_ICCV</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zonneveld, Anne and Gatt, Albert and Calixto, Iacer}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Video-and-Language (VidL) models and their cognitive relevance}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) Workshops}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{325-338}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/Drug-related_visual-summary-480.webp 480w,/assets/img/publication_preview/Drug-related_visual-summary-800.webp 800w,/assets/img/publication_preview/Drug-related_visual-summary-1400.webp 1400w," sizes="80vw,80vh" type="image/webp"> <img src="/assets/img/publication_preview/Drug-related_visual-summary.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Drug-related_visual-summary.jpg" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="MURPHY2023154292" class="col-sm-8"> <div class="title">Drug-related causes attributed to acute kidney injury and their documentation in intensive care patients</div> <div class="author"> Rachel M. Murphy ,  Dave A. Dongelmans ,  Izak Yasrebi-de Kom ,  <em>Iacer Calixto</em> ,  Ameen Abu-Hanna ,  Kitty J. Jager ,  Nicolette F. de Keizer ,  and  Joanna E. Klopotowska </div> <div class="periodical"> <em>Journal of Critical Care</em>, Oct 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://pubmed.ncbi.nlm.nih.gov/36959015/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Purpose To investigate drug-related causes attributed to acute kidney injury (DAKI) and their documentation in patients admitted to the Intensive Care Unit (ICU). Methods This study was conducted in an academic hospital in the Netherlands by reusing electronic health record (EHR) data of adult ICU admissions between November 2015 to January 2020. First, ICU admissions with acute kidney injury (AKI) stage 2 or 3 were identified. Subsequently, three modes of DAKI documentation in EHR were examined: diagnosis codes (structured data), allergy module (semi-structured data), and clinical notes (unstructured data). Results n total 8124 ICU admissions were included, with 542 (6.7%) ICU admissions experiencing AKI stage 2 or 3. The ICU physicians deemed 102 of these AKI cases (18.8%) to be drug-related. These DAKI cases were all documented in the clinical notes (100%), one in allergy module (1%) and none via diagnosis codes. The clinical notes required the highest time investment to analyze. Conclusions Drug-related causes comprise a substantial part of AKI in the ICU patients. However, current unstructured DAKI documentation practice via clinical notes hampers our ability to gain better insights about DAKI occurrence. Therefore, both automating DAKI identification from the clinical notes and increasing structured DAKI documentation should be encouraged.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">MURPHY2023154292</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Drug-related causes attributed to acute kidney injury and their documentation in intensive care patients}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Critical Care}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{75}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{154292}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0883-9441}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.jcrc.2023.154292}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S0883944123000412}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Murphy, Rachel M. and Dongelmans, Dave A. and Kom, Izak Yasrebi-de and Calixto, Iacer and Abu-Hanna, Ameen and Jager, Kitty J. and {de Keizer}, Nicolette F. and Klopotowska, Joanna E.}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Electronic health records, Acute kidney injury, Nephrotoxicity, Phenotype algorithm, Adverse drug event, Automated identification}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/Soft-prompt-tuning_Fig1-480.webp 480w,/assets/img/publication_preview/Soft-prompt-tuning_Fig1-800.webp 800w,/assets/img/publication_preview/Soft-prompt-tuning_Fig1-1400.webp 1400w," sizes="80vw,80vh" type="image/webp"> <img src="/assets/img/publication_preview/Soft-prompt-tuning_Fig1.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Soft-prompt-tuning_Fig1.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="10.1007/978-3-031-34344-5_23" class="col-sm-8"> <div class="title">Soft-Prompt Tuning to Predict Lung Cancer Using Primary Care Free-Text Dutch Medical Notes</div> <div class="author"> Auke Elfrink ,  Iacopo Vagliano ,  Ameen Abu-Hanna ,  and  <em>Iacer Calixto</em> </div> <div class="periodical"> <em>In Artificial Intelligence in Medicine</em> , Oct 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://link.springer.com/chapter/10.1007/978-3-031-34344-5_23" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://bitbucket.org/aumc-kik/prompt_tuning_cancer_prediction/src/master/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>We examine the use of large Transformer-based pretrained language models (PLMs) for the problem of early prediction of lung cancer using free-text patient medical notes of Dutch primary care physicians. Specifically, we investigate: 1) how soft prompt-tuning compares to standard model fine-tuning; 2) whether simpler static word embedding models (WEMs) can be more robust compared to PLMs in highly imbalanced settings; and 3) how models fare when trained on notes from a small number of patients. All our code is available open source in https://bitbucket.org/aumc-kik/prompt_tuning_cancer_prediction/.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10.1007/978-3-031-34344-5_23</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Elfrink, Auke and Vagliano, Iacopo and Abu-Hanna, Ameen and Calixto, Iacer}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Juarez, Jose M. and Marcos, Mar and Stiglic, Gregor and Tucker, Allan}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Soft-Prompt Tuning to Predict Lung Cancer Using Primary Care Free-Text Dutch Medical Notes}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Artificial Intelligence in Medicine}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer Nature Switzerland}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Cham}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{193--198}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-3-031-34344-5}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%69.%63%6F%69%6D%62%72%61@%61%6D%73%74%65%72%64%61%6D%75%6D%63.%6E%6C" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://github.com/nlp4health-lab" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/iacercalixto" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://twitter.com/CalixtoIacer" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> </div> <div class="contact-note">You find us at J1b-115.1 at the Amsterdam UMC location AMC on Wed/Thu, or online / by email otherwise. </div> </div> </article> </div> </div> <footer class="sticky-bottom mt-5 social" role="contentinfo"> <div class="container"> © Copyright 2025 Iacer Calixto. <a href="https://nlp4health-lab.github.io/">Impressum</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?7254ae07fe9cc5f3a10843e1c0817c9c" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>